{
  "2": {
    "inputs": {
      "vae_name": "qwen_image_vae.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Load VAE"
    }
  },
  "3": {
    "inputs": {
      "clip_name": "qwen_2.5_vl_7b_fp8_scaled.safetensors",
      "type": "qwen_image",
      "device": "default"
    },
    "class_type": "CLIPLoader",
    "_meta": {
      "title": "Load CLIP"
    }
  },
  "4": {
    "inputs": {
      "shift": 3.1000000000000005,
      "model": [
        "9",
        0
      ]
    },
    "class_type": "ModelSamplingAuraFlow",
    "_meta": {
      "title": "ModelSamplingAuraFlow"
    }
  },
  "5": {
    "inputs": {
      "text": "cyberpunk googles, photorealistic",
      "clip": [
        "3",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Positive Prompt)"
    }
  },
  "6": {
    "inputs": {
      "samples": [
        "11",
        0
      ],
      "vae": [
        "2",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "8": {
    "inputs": {
      "text": "低分辨率，低画质，肢体畸形，手指畸形，画面过饱和，蜡像感，人脸无细节，过度光滑，画面具有AI感。构图混乱。文字模糊，扭曲",
      "clip": [
        "3",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Negative Prompt)"
    }
  },
  "9": {
    "inputs": {
      "lora_name": "Qwen-Image-Lightning-4steps-V1.0.safetensors",
      "strength_model": 1,
      "model": [
        "15",
        0
      ]
    },
    "class_type": "LoraLoaderModelOnly",
    "_meta": {
      "title": "Load LoRA"
    }
  },
  "11": {
    "inputs": {
      "seed": 438660934735493,
      "steps": 4,
      "cfg": 1,
      "sampler_name": "euler",
      "scheduler": "simple",
      "denoise": 1,
      "model": [
        "4",
        0
      ],
      "positive": [
        "21",
        0
      ],
      "negative": [
        "21",
        1
      ],
      "latent_image": [
        "20",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "12": {
    "inputs": {
      "filename_prefix": "ComfyUI",
      "images": [
        "6",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  },
  "15": {
    "inputs": {
      "unet_name": "qwen-image-2512-Q8_0.gguf"
    },
    "class_type": "UnetLoaderGGUF",
    "_meta": {
      "title": "Unet Loader (GGUF)"
    }
  },
  "16": {
    "inputs": {
      "image": "clipspace/clipspace-painted-masked-1769773085660.png [input]"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "18": {
    "inputs": {
      "pixels": [
        "16",
        0
      ],
      "vae": [
        "2",
        0
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE Encode"
    }
  },
  "20": {
    "inputs": {
      "samples": [
        "18",
        0
      ],
      "mask": [
        "19:253",
        0
      ]
    },
    "class_type": "SetLatentNoiseMask",
    "_meta": {
      "title": "Set Latent Noise Mask"
    }
  },
  "21": {
    "inputs": {
      "strength": 1,
      "start_percent": 0,
      "end_percent": 1,
      "positive": [
        "5",
        0
      ],
      "negative": [
        "8",
        0
      ],
      "control_net": [
        "24",
        0
      ],
      "vae": [
        "2",
        0
      ],
      "image": [
        "16",
        0
      ],
      "mask": [
        "19:253",
        0
      ]
    },
    "class_type": "ControlNetInpaintingAliMamaApply",
    "_meta": {
      "title": "ControlNetInpaintingAliMamaApply"
    }
  },
  "24": {
    "inputs": {
      "control_net_name": "Qwen-Image-InstantX-ControlNet-Inpainting.safetensors"
    },
    "class_type": "ControlNetLoader",
    "_meta": {
      "title": "Load ControlNet Model"
    }
  },
  "19:253": {
    "inputs": {
      "channel": "red",
      "image": [
        "19:252",
        0
      ]
    },
    "class_type": "ImageToMask",
    "_meta": {
      "title": "Convert Image to Mask"
    }
  },
  "19:251": {
    "inputs": {
      "mask": [
        "19:199",
        0
      ]
    },
    "class_type": "MaskToImage",
    "_meta": {
      "title": "Convert Mask to Image"
    }
  },
  "19:199": {
    "inputs": {
      "expand": 0,
      "tapered_corners": true,
      "mask": [
        "16",
        1
      ]
    },
    "class_type": "GrowMask",
    "_meta": {
      "title": "Grow Mask"
    }
  },
  "19:252": {
    "inputs": {
      "blur_radius": 31,
      "sigma": 1,
      "image": [
        "19:251",
        0
      ]
    },
    "class_type": "ImageBlur",
    "_meta": {
      "title": "ImageBlur"
    }
  }
}